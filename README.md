# Augmented-Facial-Expression-Filter
# ğŸ­ Emotion-Based Real-Time Face Filter with OpenCV, MediaPipe & FER

Welcome to **Emotion Filter**, an intelligent real-time facial augmentation project that detects human emotions via webcam and overlays expressive AR-style filters based on detected mood. This project combines the power of **computer vision**, **facial landmark tracking**, and **AI-driven emotion detection** to create an engaging and interactive experience.

## âœ¨ Features

- ğŸ” **Real-time Emotion Detection** using the FER (Facial Expression Recognition) deep learning model.
- ğŸ§  **Facial Landmark Tracking** with MediaPipe for precise overlay placement.
- ğŸ•¶ï¸ **Augmented Reality Filters** tailored to each emotion:
  - ğŸ˜„ *Happy* â€“ Cool sunglasses + smiling mouth overlay
  - ğŸ˜  *Angry* â€“ Devil horns + mustache
  - ğŸ˜² *Surprised* â€“ Wide surprised glasses + open shocked mouth
  - ğŸ˜ *Neutral* â€“ Neutral face overlay (optional)
- ğŸ“· Seamless webcam integration via OpenCV.

## ğŸ§° Tech Stack

| Technology | Purpose |
|-----------|---------|
| `Python` | Core language |
| `OpenCV` | Webcam access, frame processing, image rendering |
| `MediaPipe` | Facial landmark detection (468 3D points) |
| `FER` | Deep learning-based emotion classifier |
| `NumPy` | Efficient numerical computations and vector operations |

## ğŸ§  How It Works

1. **Capture Frame:** Live video is captured using OpenCV from the default webcam.
2. **Detect Emotion:** FER processes the RGB frame to determine facial emotions like *happy*, *angry*, or *surprised*.
3. **Extract Landmarks:** MediaPipe FaceMesh identifies key facial points such as eyes, lips, and forehead.
4. **Render Filter:** Based on the detected emotion, a corresponding transparent PNG filter is resized and overlaid on facial landmarks using precise alpha blending.



